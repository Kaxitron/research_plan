# Lesson 41: The Forward Pass as Matrix Multiplications

[â† Single Neuron](lesson-40-single-neuron.md) | [Back to TOC](../README.md) | [Next: Backpropagation â†’](lesson-42-backprop.md)

---

## ğŸ¯ Core Learning

- A layer of neurons = single matrix multiplication + bias + activation
- The forward pass: input â†’ layer 1 â†’ layer 2 â†’ ... â†’ output
- This is just composition of functions! fâ‚ƒ(fâ‚‚(fâ‚(x)))
- Batch processing: multiple inputs simultaneously (wider matrices)
- Every matrix IS a linear transformation â€” Lessons 2-9 apply directly
- Softmax: turning raw scores into probabilities
- **The geometric view:** each ReLU "folds" space; layers compose these folds into rich, piecewise-linear decision boundaries

## ğŸ“º Watch â€” Primary

1. **Welch Labs â€” "The Misconception that Almost Stopped AI [How Models Learn Part 1]"**
   - https://www.youtube.com/@WelchLabs (search "How Models Learn Part 1")
   - *22 minutes. The Belgium/Netherlands map example is PERFECT for your geometric intuition style. Each neuron folds a plane; stacking layers composes folds. You'll see WHY deep networks work. This is the single best visual for understanding what a forward pass actually does to data.*

2. **Karpathy â€” "Building makemore" (Lecture 2)**
   - https://www.youtube.com/watch?v=PaCmpygFfXo
3. **Karpathy â€” "Building makemore Part 2: MLP" (Lecture 3)**
   - https://www.youtube.com/watch?v=TCH_1BHY58I

## ğŸ“º Watch â€” Secondary

4. **Nelson Elhage â€” "Transformers for Software Engineers"** (blog/talk)
   - https://blog.nelhage.com/post/transformers-for-software-engineers/

## ğŸ“– Read

- **Nelson Elhage â€” "Transformers for Software Engineers"**
  - https://blog.nelhage.com/post/transformers-for-software-engineers/

## ğŸ”¨ Do

- Implement a 2-layer MLP from scratch in NumPy (no PyTorch)
- Train on MNIST digit classification
- Visualize weight matrices as images â€” what patterns do they learn?
- **Key geometric exercise:** For a 2D classification problem, visualize the decision boundary at each layer. Watch the folds happen.

## ğŸ”— ML Connection

When interpretability researchers say "the model moves information through the residual stream," they mean each matrix multiplication's output gets added back to a running total. Understanding the forward pass as composed matrix multiplications is THE prerequisite for reading Anthropic's papers.

The Welch Labs "folding" framing also explains why **depth matters more than width**: adding a layer adds another fold; adding width just makes each fold more complex. A deep network can approximate any function with far fewer neurons than a wide shallow one.
