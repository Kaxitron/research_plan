# Lesson 54: Groups â€” Symmetry as Mathematics

[â† Kolmogorov Complexity](lesson-53-kolmogorov-complexity.md) | [Back to TOC](../README.md) | [Next: Rings & Fields â†’](lesson-55-rings-fields.md)

---

> **Why this lesson exists:** A group is the mathematical formalization of symmetry â€” the set of all ways to transform something while preserving its structure. Groups appear throughout ML: the permutation symmetry of neural network neurons, the rotation/translation invariance of convolutions, the gauge symmetries of weight space. Understanding groups gives you the language to describe these symmetries precisely, and symmetry is the key to understanding the singularities that SLT studies.

## ğŸ¯ Core Concepts

### What Is a Group?

- **A group (G, Â·)** is a set G with a binary operation Â· satisfying four axioms:
  1. **Closure:** a Â· b âˆˆ G for all a, b âˆˆ G
  2. **Associativity:** (a Â· b) Â· c = a Â· (b Â· c)
  3. **Identity:** there exists e âˆˆ G such that e Â· a = a Â· e = a for all a
  4. **Inverse:** for each a âˆˆ G there exists aâ»Â¹ such that a Â· aâ»Â¹ = aâ»Â¹ Â· a = e
- **Groups capture symmetry:** the set of all symmetries of any object forms a group. The operation is composition (do one symmetry, then another). The identity is "do nothing." The inverse undoes a symmetry.

### Essential Examples

- **â„¤_n (integers mod n):** {0, 1, ..., n-1} under addition mod n. The symmetries of a clock face. â„¤_2 = {0,1} is the simplest non-trivial group.
- **S_n (symmetric group on n elements):** all permutations of {1,...,n}. This group has n! elements. S_3 has 6 elements and is the first non-abelian group you'll encounter (ab â‰  ba in general).
- **GL(n,â„) (general linear group):** all invertible nÃ—n real matrices under multiplication. You've been working with this group since Phase 1 â€” every invertible matrix is a symmetry of â„â¿.
- **O(n) and SO(n):** orthogonal and special orthogonal groups â€” rotations and reflections. These are the symmetries that preserve distances (isometries). They appear in data augmentation and equivariant neural networks.

### Subgroups, Cosets, and Quotients

- **A subgroup H â‰¤ G** is a subset that's itself a group under the same operation. Example: even permutations form a subgroup A_n â‰¤ S_n.
- **Lagrange's theorem:** the order of a subgroup divides the order of the group: |H| divides |G|. This is a powerful counting tool.
- **Cosets:** gH = {gh : h âˆˆ H} is a left coset of H. Cosets partition G into equal-sized pieces. The number of cosets is |G|/|H| (the index).
- **Normal subgroups and quotient groups:** if H is normal in G (gHgâ»Â¹ = H for all g), you can form the quotient group G/H, whose elements are the cosets. This is "collapsing" the symmetry of H â€” treating everything related by H as identical.
- **For neural networks:** neurons that are permutations of each other are related by the symmetric group S_n acting on hidden units. The "true" weight space is the quotient W/S_n â€” weight space modulo permutation symmetry. This quotient structure creates the singularities that SLT studies.

### Homomorphisms and Isomorphisms

- **A homomorphism** Ï†: G â†’ H is a map that preserves the group operation: Ï†(ab) = Ï†(a)Ï†(b). It's a "structure-preserving translation" between groups.
- **An isomorphism** is a bijective homomorphism â€” two groups are "the same" if isomorphic.
- **The kernel** ker(Ï†) = {g âˆˆ G : Ï†(g) = e_H} is a normal subgroup of G. **The first isomorphism theorem:** G/ker(Ï†) â‰… im(Ï†). The quotient by the kernel equals the image.
- **For ML:** the map from weight space to function space is a homomorphism (under appropriate operations). Its kernel â€” the set of weight configurations that compute the same function â€” is the symmetry group of the network. The first isomorphism theorem says: function space â‰… weight space / symmetry group.

### Abelian vs Non-Abelian Groups

- **Abelian (commutative):** ab = ba for all a, b. Examples: â„¤, â„¤_n, (â„â¿, +).
- **Non-abelian:** ab â‰  ba in general. Examples: S_n for n â‰¥ 3, GL(n) for n â‰¥ 2, rotation group SO(3).
- **Most symmetry groups in ML are non-abelian:** permuting neuron 1 and 2, then permuting 2 and 3, gives a different result than the reverse order. Non-commutativity creates richer structure (and more complex singularities).

## ğŸ“º Watch â€” Primary

1. **3Blue1Brown â€” groups and symmetry (if available)**
2. **Visual Group Theory â€” "What is a Group?" (Nathan Carter lectures)**

## ğŸ“– Read â€” Primary

- **"Visual Group Theory" by Nathan Carter** â€” Chapters 1â€“6
  - *The most visual and intuitive introduction to group theory available.*
- **"Algebra: Chapter 0" by Aluffi** â€” Chapter 1â€“2 (if you want more rigor)

## ğŸ”¨ Do

- Write out the full multiplication table for Sâ‚ƒ (6 elements). Find all subgroups. Verify Lagrange's theorem.
- Prove that the set of nÃ—n orthogonal matrices forms a group under multiplication. What's the identity? What's the inverse of an element?
- Implement a permutation group in Python: represent permutations as lists, implement composition and inversion. Verify the group axioms computationally for Sâ‚„.
- Show that for a 2-hidden-unit neural network, swapping the two hidden units (a specific element of Sâ‚‚) gives the same function. Write this as a group action on weight space.

## ğŸ§  Alignment Connection

**Permutation symmetries** in neural networks (swapping neurons gives the same function) create degenerate regions in the loss landscape. These symmetries mean many different weight configurations compute the same function â€” making it harder to verify whether a model has learned "safe" vs "unsafe" behavior by inspecting weights alone. In Singular Learning Theory, these symmetries create the singularities that determine generalization. Understanding group theory is prerequisite to understanding *why* neural networks generalize the way they do.
