# Exam 5B: Topology and Formal Logic

**The Path to AI Alignment ‚Äî Lessons 57‚Äì62 Comprehensive Assessment**

---

| | |
|---|---|
| **Time Allowed** | 60 minutes |
| **Total Points** | 100 |
| **Materials** | Pencil, paper. No calculator needed. |
| **Format** | 10 questions mixing proofs, computation, and conceptual depth |

> **Advice:** This exam covers the most abstract material in the curriculum. The thread: **topology gives structure to spaces where optimization lives, algebraic geometry resolves the singularities SLT studies, and logic reveals fundamental limits on self-referential reasoning about safety.**

---

## Question 1 (10 pts) ‚Äî Point-Set Topology

**(a)** In the standard topology on ‚Ñù, is the set (0, 1) open, closed, both, or neither? What about [0, 1]? What about [0, 1)?

**(b)** Define compactness. State (without proof) the Heine-Borel theorem for ‚Ñù‚Åø.

**(c)** Why does compactness matter for optimization? Specifically: if f is a continuous function on a compact set K, what can you guarantee about f's maximum and minimum? (State the extreme value theorem.)

**(d)** A loss function L: W ‚Üí ‚Ñù is continuous and W is all of ‚Ñù·µà (not compact). Why doesn't the extreme value theorem apply directly? What practical trick do we use to recover compactness? *(Hint: weight decay / regularization.)*

---

## Question 2 (10 pts) ‚Äî Connectedness and Continuity

**(a)** Define what it means for a topological space to be connected.

**(b)** Is the set {x ‚àà ‚Ñù : x¬≤ < 4} connected? Is the set {x ‚àà ‚Ñù : x¬≤ > 4} connected? Explain.

**(c)** In the context of loss landscapes: if the set of global minima {W : L(W) = L*} is connected, what does this mean for training? What if it's disconnected?

**(d)** If two loss minima are in the same connected component, can gradient descent always find a path between them? Why or why not?

---

## Question 3 (10 pts) ‚Äî Homotopy and Fundamental Groups

**(a)** Define a homotopy between two continuous maps. When are two paths "homotopic"?

**(b)** The fundamental group œÄ‚ÇÅ(X, x‚ÇÄ) captures "loops that can't be shrunk." Compute (or state) œÄ‚ÇÅ for: (i) ‚Ñù¬≤, (ii) the circle S¬π, (iii) the torus T¬≤.

**(c)** A loss landscape sublevel set S_Œµ = {W : L(W) ‚â§ Œµ} might have "holes" (non-trivial fundamental group). What would the presence of a hole mean for gradient-based optimization?

**(d)** The topology of level sets can change as Œµ varies ‚Äî this is the essence of Morse theory. How does this connect to critical points of the loss function?

---

## Question 4 (10 pts) ‚Äî Manifolds and Tangent Spaces

**(a)** Define a smooth manifold informally. Give two examples from everyday experience.

**(b)** What is the tangent space T_pM at a point p on a manifold M? Why is it useful for optimization?

**(c)** Weight space modulo the permutation symmetry S_n (i.e., identifying equivalent weight configurations) is NOT a manifold everywhere ‚Äî it has singular points. Where do these singularities occur? *(Hint: think about the orbit-stabilizer theorem from Lesson 56.)*

**(d)** Riemannian gradient descent generalizes gradient descent to manifolds. In one sentence, explain the key idea: how is the gradient adapted to a curved space?

---

## Question 5 (12 pts) ‚Äî Algebraic Geometry and Singularities

**(a)** Define an algebraic variety. Give two examples: one smooth, one singular.

**(b)** How do you determine if a point on a variety is smooth or singular? State the Jacobian criterion.

**(c)** Classify the singularity type for each variety at the origin: (i) V = {y¬≤ ‚àí x¬≤ = 0}, (ii) V = {y¬≤ ‚àí x¬≥ = 0}.

**(d)** Describe what a blow-up does geometrically to the node V = {y¬≤ ‚àí x¬≤ = 0} at the origin. After the blow-up, is the singularity resolved?

**(e)** Compute the RLCT for f(w) = w‚Å∂ in 1D. *(Hint: the integral ‚à´‚ÇÄ¬π w^{‚àí6t} dw converges iff...)*

---

## Question 6 (10 pts) ‚Äî The RLCT: Full Chain

**(a)** State the chain connecting permutation symmetry to the RLCT:
permutation symmetry ‚Üí ___ ‚Üí ___ ‚Üí ___ ‚Üí RLCT

**(b)** For a simple model f(w‚ÇÅ, w‚ÇÇ) = w‚ÇÅ¬≤w‚ÇÇ¬≤ (the product-of-squares singularity), the set {f = 0} is two crossing lines. After blowing up, the singularity resolves. The RLCT is Œª = 1/2. Compare with the "regular" value d/2 = 2/2 = 1 for 2 parameters. What does the 2√ó reduction mean?

**(c)** Hironaka's theorem guarantees that ANY variety can be resolved by a finite sequence of blow-ups. Why is this theorem essential for SLT?

---

## Question 7 (10 pts) ‚Äî Propositional and Predicate Logic

**(a)** Translate into propositional logic: "If the model is deceptive and passes behavioral tests, then interpretability is necessary for detecting misalignment." Define your variables clearly.

**(b)** Construct a truth table for (P ‚Üí Q) ‚àß (¬¨Q). What does this compound statement simplify to?

**(c)** Translate into predicate logic: "For every input, if the model produces a harmful output, then the safety filter catches it." Use ‚àÄ, ‚Üí, and appropriate predicates.

**(d)** Formalize the following safety property in predicate logic: "There exists no input for which the model produces harmful output and the safety filter fails to catch it."

---

## Question 8 (10 pts) ‚Äî G√∂del's Incompleteness Theorems

**(a)** State G√∂del's first incompleteness theorem informally.

**(b)** The G√∂del sentence G says "this sentence is not provable." Explain why G is TRUE but UNPROVABLE in the system.

**(c)** State G√∂del's second incompleteness theorem. What does it say about a system proving its own consistency?

**(d)** For alignment: if an AI system uses a formal logical system for reasoning, what do G√∂del's theorems imply about the system's ability to prove its own safety? Be specific.

---

## Question 9 (10 pts) ‚Äî L√∂b's Theorem and Self-Reference

**(a)** State L√∂b's theorem: if a system can prove "if I can prove P, then P," what follows?

**(b)** Explain the "L√∂bian obstacle" to AI self-trust: why can't an AI system simply prove "if I can prove I'm safe, then I am safe" and use this to bootstrap a safety guarantee?

**(c)** Two AI systems, A and B, want to cooperate but each needs to trust the other's safety proofs. Explain how L√∂b's theorem constrains this mutual verification.

**(d)** Despite these limits, some researchers propose "L√∂bian handshakes" or alternative logical frameworks. In 1‚Äì2 sentences, explain why finding workarounds to L√∂b's theorem matters for AI coordination.

---

## Question 10 (8 pts) ‚Äî Capstone Synthesis

Trace the complete chain from permutation symmetry to L√∂b's theorem:

**(a)** Permutation symmetry (Lesson 56) ‚Üí singularity in weight space ‚Üí blow-up resolution (Lesson 60) ‚Üí RLCT computation ‚Üí free energy formula.
For each arrow, write one sentence explaining the mathematical mechanism.

**(b)** In 3‚Äì4 sentences, explain why BOTH the algebraic geometry thread (singularities, RLCT) AND the logic thread (G√∂del, L√∂b) are necessary for a complete mathematical approach to alignment. What does each contribute that the other cannot?

---

## üîß Optional Mini Project (~45 minutes): Topological Data Analysis on Neural Network Activations

**Use persistent homology to analyze the shape of learned representations.**

1. Train a small network (MLP or CNN) on a subset of MNIST (just digits 0, 1, 2 for simplicity)
2. Extract the hidden layer activations for 500 test samples
3. Use a TDA library (e.g., `ripser`, `gudhi`, or `giotto-tda`) to compute the persistent homology of the activation point cloud
4. Plot the persistence diagram: each point represents a topological feature (connected component, loop, void) with its birth and death times
5. Interpret: how many distinct clusters does the network create? (H‚ÇÄ features = connected components.) Are there any loops (H‚ÇÅ features)?
6. Compare: run the same analysis on the raw pixel inputs (before the network). Show that the network has "simplified" the topology ‚Äî fewer, more separated clusters

**Stretch:** Track how the persistence diagram changes across training epochs. Does the topology simplify as the network learns?

**Tools:** PyTorch, ripser or giotto-tda, Matplotlib.
