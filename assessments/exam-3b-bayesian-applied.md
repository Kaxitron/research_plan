# Exam 3B: Bayesian Deep Dive & Applied Statistics â€” The Paradigm Shift

**The Path to AI Alignment â€” Lessons 35â€“39 Comprehensive Assessment**

---

| | |
|---|---|
| **Time Allowed** | 60 minutes |
| **Total Points** | 100 |
| **Materials** | Pencil, paper, calculator (no CAS). No code. |
| **Format** | 10 questions mixing computation and conceptual depth |

> **Advice:** The thread: **Bayesian reasoning unifies learning, regularization, and model comparison â€” and connects directly to SLT.**

---

## Question 1 (10 pts) â€” Bayesian Foundations

**(a)** Write Bayes' theorem in the form: posterior âˆ likelihood Ã— prior. Label each term in the context of training a model with parameters Î¸ on data D.

**(b)** You flip a coin 10 times and get 7 heads. With a uniform prior on Î¸ (probability of heads), the posterior is Beta(8, 4). What is the posterior mean? How does this compare to the MLE?

**(c)** Now use a strong prior: Beta(100, 100) (strongly believe Î¸ â‰ˆ 0.5). After seeing 7/10 heads, the posterior is approximately Beta(107, 103). What is the posterior mean? Why has the prior "overwhelmed" the data?

**(d)** In one sentence: when is the Bayesian approach most different from MLE, and when do they converge?

---

## Question 2 (12 pts) â€” MAP and Regularization

**(a)** The MAP estimate is Î¸_MAP = argmax P(Î¸|D) = argmax [log P(D|Î¸) + log P(Î¸)]. Show that if the prior is P(Î¸) âˆ exp(âˆ’Î»â€–Î¸â€–Â²), then MAP is equivalent to MLE with L2 regularization (Ridge).

**(b)** What prior corresponds to L1 regularization (Lasso)?

**(c)** Ridge works best when "everything matters a little." Lasso works best when "most things don't matter." Explain these intuitions in terms of the prior distribution shapes.

**(d)** Weight decay in neural network training is equivalent to what Bayesian prior? What does this tell you about what we implicitly believe about good weight configurations?

---

## Question 3 (10 pts) â€” MCMC and Variational Inference

**(a)** The posterior P(Î¸|D) âˆ P(D|Î¸)P(Î¸) is usually intractable. Name the two main approaches to handling this and state one advantage of each.

**(b)** Metropolis-Hastings proposes a new Î¸' and accepts it with probability min(1, P(Î¸'|D)/P(Î¸|D)). Why doesn't this require computing the normalizing constant P(D)?

**(c)** Variational inference approximates P(Î¸|D) with a simpler distribution q(Î¸) by minimizing KL(q â€– P(Î¸|D)). This leads to maximizing the ELBO. Write the ELBO: ELBO(q) = E_q[log P(D|Î¸)] âˆ’ KL(q â€– P(Î¸)). Why is the ELBO a lower bound on log P(D)?

**(d)** The ELBO appears again in VAE training. In 2â€“3 sentences, explain the connection: what plays the role of Î¸, what plays the role of D, and what is q?

---

## Question 4 (10 pts) â€” Bayesian Model Comparison

**(a)** The marginal likelihood (evidence) is P(D|M) = âˆ« P(D|Î¸,M)P(Î¸|M) dÎ¸. Explain in 2â€“3 sentences why this automatically penalizes overly complex models (Occam's razor as a theorem).

**(b)** BIC approximates 2Â·log P(D|M) â‰ˆ 2Â·log P(D|Î¸Ì‚) âˆ’ kÂ·log(n), where k = parameter count, n = sample size. What does the âˆ’kÂ·log(n) term do?

**(c)** BIC assumes the model is *regular* (the parameter-to-function map is locally one-to-one). Neural networks are singular (many parameters â†’ same function). What goes wrong with BIC for neural networks?

**(d)** In SLT, the RLCT Î» replaces k/2 in the free energy formula: F â‰ˆ Î»Â·log(n). Why is Î» â‰¤ k/2 always, and what does this inequality mean for neural network generalization?

---

## Question 5 (10 pts) â€” Causal Inference

**(a)** Draw a causal DAG for: "Education â†’ Income, Education â†’ Health, Income â†’ Health, Confounders â†’ Education, Confounders â†’ Health." Identify a backdoor path from Education to Health.

**(b)** What is a confounder? In your DAG, identify one and explain how it could bias a naive estimate of Education's effect on Health.

**(c)** An observational study finds that hospitals with more ICU beds have higher mortality rates. Explain why this doesn't mean ICU beds cause death. *(What is this an example of?)*

**(d)** Describe in 2â€“3 sentences how counterfactual reasoning is central to AI alignment. *(Hint: decision theory asks "what would happen if...")*

---

## Question 6 (10 pts) â€” Applied Statistics: Heritability and GWAS

**(a)** Heritability hÂ² = Var(genetic)/Var(total). If hÂ² = 0.8 for height, does this mean 80% of YOUR height is determined by genes? Explain the correct interpretation.

**(b)** GWAS finds SNPs associated with traits. A study finds 1000 SNPs each explaining 0.01% of variance in IQ. Combined they explain 10%. But twin studies suggest hÂ² â‰ˆ 0.5. What is this discrepancy called, and name two possible explanations.

**(c)** A study uses regression to show that after controlling for education and income, there's still a correlation between genes and a behavioral trait. Explain why "controlling for" post-treatment variables (education, income) can actually INTRODUCE bias rather than remove it.

**(d)** State one way the statistical tools from this phase (hypothesis testing, regression, causal inference) directly apply to evaluating claims about AI model capabilities.

---

## Question 7 (8 pts) â€” The Free Energy Principle

**(a)** Write the free energy: F = âˆ’log P(D) = âˆ’log âˆ« P(D|Î¸)P(Î¸)dÎ¸. For regular models, F â‰ˆ nL* + (k/2)log(n). For singular models, F â‰ˆ nL* + Î»Â·log(n). Define each variable.

**(b)** Two models fit the same data equally well (same L*). Model A has k=100 parameters (regular). Model B is a neural network with k=10,000 parameters but RLCT Î»=30. Which does Bayesian model comparison prefer, and why?

**(c)** Explain in one sentence why "neural networks have too many parameters to generalize" is wrong according to SLT.

---

## Question 8 (10 pts) â€” Frequentist vs. Bayesian Showdown

A medical device has a defect rate Î¸. You observe 0 defects in 100 tests.

**(a)** Frequentist: the MLE is Î¸Ì‚ = 0. A 95% confidence interval (using the rule of three) is approximately [0, 3/100] = [0, 0.03]. Interpret this.

**(b)** Bayesian with uniform prior Beta(1,1): posterior is Beta(1, 101). The posterior mean is 1/102 â‰ˆ 0.0098. The 95% credible interval is approximately [0.0001, 0.036]. Why is the Bayesian estimate nonzero even though no defects were observed?

**(c)** Which approach would you use to evaluate the safety of an AI system that has never exhibited dangerous behavior in testing? Justify your choice in 2â€“3 sentences.

---

## Question 9 (10 pts) â€” Synthesis: Adjudicating a Statistical Claim

A blog post claims: "Study shows that GPT-5 has emergent deceptive capabilities, p = 0.02."

Using everything from Lessons 28â€“39, write a 5-point critique evaluating this claim. Address: the study design, the p-value interpretation, potential confounders, Bayesian considerations, and what additional evidence you'd want.

---

## Question 10 (10 pts) â€” The Bayesian-SLT Bridge

**(a)** The Bayesian posterior concentrates around the MAP as n â†’ âˆž (Bernstein-von Mises theorem) â€” but only for regular models. Why does this fail for singular models?

**(b)** SLT says the posterior for singular models concentrates around the set of optimal parameters K (a variety, not a point). The RLCT measures the "width" of K. Connect this to the concept of flat minima from the calculus phase.

**(c)** In your own words: how does the Bayesian framework's automatic Occam's razor (penalizing complexity via the marginal likelihood) connect to the observation that overparameterized neural networks generalize well?

---

## ðŸ”§ Optional Mini Project (~45 minutes): Bayesian A/B Testing Dashboard

**Build a Bayesian A/B test analyzer that updates beliefs in real time.**

1. Simulate an A/B test: version A converts at 5%, version B at 6% (small true difference). Generate click data sequentially.
2. Model each version's conversion rate with a Beta prior (start with Beta(1,1) = uniform)
3. After each batch of 50 observations, update the posterior for both versions. Plot the two posterior distributions overlaid.
4. Compute and plot over time: (a) P(B > A), (b) expected lift E[Bâˆ’A], (c) 95% credible interval for the difference
5. Compare: at what sample size does the Bayesian approach become "confident" (P(B>A) > 0.95) vs. when the frequentist p-value crosses 0.05?
6. Show how a strong prior (Beta(100,100)) slows down learning â€” the posterior is "stubborn"

**Stretch:** Add a decision-theoretic layer. Given a cost per observation and a revenue per conversion, compute the expected value of continuing to test vs. deploying B now. Find the optimal stopping point.

**Tools:** NumPy, Matplotlib, SciPy (for Beta distribution).
