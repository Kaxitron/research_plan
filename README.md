# The Path to AI Alignment

## A Complete Self-Study Curriculum: Mathematics â†’ Neural Networks â†’ Alignment

---

**Goal:** Develop deep intuitive understanding of the mathematics underlying neural networks, the architecture and philosophy of modern AI systems, and the tools of mechanistic interpretability â€” all in service of solving AI alignment.

**Your profile:** Good mathematical intuition, intermediate C++/Python, refreshing math after a 6-year gap. You learn best through geometric intuition first, then mechanics. Pace: ~33% slower than typical technical presentation.

**Estimated total time:** 6â€“8 months at a steady pace.

---

## Table of Contents

### [PHASE 0: Prerequisites](phase0-prerequisites/)
*Tools and foundations before the math begins*

| # | Lesson | Status |
|---|--------|--------|
| 0b | [PyTorch â€” The Language of Alignment Research](phase0-prerequisites/lesson-00b-pytorch.md) | â¬œ Not Started |

### [PHASE 1: Linear Algebra Foundations](phase1-linear-algebra/)
*The language that transformers speak*

| # | Lesson | Status |
|---|--------|--------|
| 1 | [Vectors â€” What They Actually Are](phase1-linear-algebra/lesson-01-vectors.md) | âœ… Complete |
| 2 | [Linear Combinations, Span, and Basis](phase1-linear-algebra/lesson-02-span-basis.md) | âœ… Complete |
| 3 | [Linear Transformations and Matrices](phase1-linear-algebra/lesson-03-transformations.md) | âœ… Complete |
| 4 | [Matrix Operations Deep Dive](phase1-linear-algebra/lesson-04-matrix-operations.md) | âœ… Complete |
| 5 | [Rank, Null Space, and Column Space](phase1-linear-algebra/lesson-05-rank-nullspace.md) | âœ… Complete |
| 6 | [The Determinant](phase1-linear-algebra/lesson-06-determinant.md) | âœ… Complete |
| 7 | [Eigenvalues and Eigenvectors](phase1-linear-algebra/lesson-07-eigenvalues.md) | âœ… Complete |
| 8 | [Singular Value Decomposition (SVD)](phase1-linear-algebra/lesson-08-svd.md) | ðŸ”„ In Progress |
| 9 | [Dot Products, Orthogonality, and Projections](phase1-linear-algebra/lesson-09-dot-products.md) | â¬œ Not Started |
| 10 | [Change of Basis, Norms, and Special Matrices](phase1-linear-algebra/lesson-10-change-of-basis.md) | â¬œ Not Started |
| 11 | [Linear Algebra Capstone](phase1-linear-algebra/lesson-11-capstone.md) | â¬œ Not Started |

### [PHASE 2: Calculus for ML](phase2-calculus/)
*The mathematical engine of neural network learning*

| # | Lesson | Status |
|---|--------|--------|
| 12 | [Matrix Calculus â€” Bridging to Backpropagation](phase2-calculus/lesson-12-matrix-calculus.md) | â¬œ Not Started |
| 13 | [Partial Derivatives and Gradients â€” Going Deeper](phase2-calculus/lesson-13-gradients.md) | â¬œ Not Started |
| 14 | [The Chain Rule â€” This IS Backpropagation](phase2-calculus/lesson-14-chain-rule.md) | â¬œ Not Started |
| 15 | [Optimization and Gradient Descent](phase2-calculus/lesson-15-optimization.md) | â¬œ Not Started |
| 16 | [Loss Landscapes and Local Minima](phase2-calculus/lesson-16-loss-landscapes.md) | â¬œ Not Started |

### [PHASE 3: Probability, Information Theory, and Bayesian Thinking](phase3-probability/)
*The language of uncertainty and learning*

| # | Lesson | Status |
|---|--------|--------|
| 17 | [Probability Distributions and Bayes' Theorem](phase3-probability/lesson-17-probability.md) | â¬œ Not Started |
| 18 | [Expectation, Variance, and Covariance](phase3-probability/lesson-18-expectation.md) | â¬œ Not Started |
| 19 | [Maximum Likelihood Estimation](phase3-probability/lesson-19-mle.md) | â¬œ Not Started |
| 20 | [Information Theory â€” Entropy, KL Divergence, Cross-Entropy, and Mutual Information](phase3-probability/lesson-20-information-theory.md) | â¬œ Not Started |
| 21 | [Bayesian Reasoning and Inference](phase3-probability/lesson-21-bayesian-inference.md) | â¬œ Not Started |

### [PHASE 3b: Mathematical Enrichment](phase3b-math-enrichment/)
*Deeper foundations for cutting-edge alignment research*

| # | Lesson | Status |
|---|--------|--------|
| 21b | [Computability and Complexity â€” The Limits of Knowledge](phase3b-math-enrichment/lesson-21b-computability.md) | â¬œ Not Started |
| 21c | [Abstract Algebra â€” Groups, Symmetry, and Neural Networks](phase3b-math-enrichment/lesson-21c-abstract-algebra.md) | â¬œ Not Started |
| 21d | [Topology and Manifolds â€” The Shape of Data and Loss](phase3b-math-enrichment/lesson-21d-topology.md) | â¬œ Not Started |
| 21e | [Differential Equations and Dynamical Systems â€” Training as Flow](phase3b-math-enrichment/lesson-21e-diff-equations.md) | â¬œ Not Started |
| 21f | [Formal Logic â€” Self-Reference, Incompleteness, and the Limits of Reason](phase3b-math-enrichment/lesson-21f-formal-logic.md) | â¬œ Not Started |

### [PHASE 4: Neural Networks â€” From Neurons to Transformers](phase4-neural-networks/)
*Building the machine, piece by piece*

| # | Lesson | Status |
|---|--------|--------|
| 22 | [How a Single Neuron Works](phase4-neural-networks/lesson-22-single-neuron.md) | â¬œ Not Started |
| 23 | [The Forward Pass as Matrix Multiplications](phase4-neural-networks/lesson-23-forward-pass.md) | â¬œ Not Started |
| 24 | [Backpropagation Through the Full Network](phase4-neural-networks/lesson-24-backprop.md) | â¬œ Not Started |
| 25 | [Attention â€” Dot Products in Action](phase4-neural-networks/lesson-25-attention.md) | â¬œ Not Started |
| 26 | [Building a Transformer from Scratch](phase4-neural-networks/lesson-26-transformer.md) | â¬œ Not Started |

### [PHASE 5: Mechanistic Interpretability](phase5-interpretability/)
*Using everything you've learned to open the black box*

| # | Lesson | Status |
|---|--------|--------|
| 27 | [What Interpretability Researchers Actually Do](phase5-interpretability/lesson-27-intro-interp.md) | â¬œ Not Started |
| 28 | [Circuits and Features in Practice](phase5-interpretability/lesson-28-circuits.md) | â¬œ Not Started |

### [PHASE 6: Alignment Theory and Foundations](phase6-alignment-theory/)
*The philosophical and strategic landscape*

| # | Lesson | Status |
|---|--------|--------|
| 29 | [Game Theory Foundations](phase6-alignment-theory/lesson-29-game-theory.md) | â¬œ Not Started |
| 30 | [Decision Theory â€” CDT, EDT, and FDT](phase6-alignment-theory/lesson-30-decision-theory.md) | â¬œ Not Started |
| 31 | [Anthropics and Self-Locating Beliefs](phase6-alignment-theory/lesson-31-anthropics.md) | â¬œ Not Started |
| 32 | [The Alignment Problem â€” Technical Foundations](phase6-alignment-theory/lesson-32-alignment-problem.md) | â¬œ Not Started |
| 33 | [Open Problems and Research Frontiers](phase6-alignment-theory/lesson-33-open-problems.md) | â¬œ Not Started |

### [PHASE 7: Independent Research](phase7-research/)

| # | Lesson | Status |
|---|--------|--------|
| â€” | [Your First Research Project](phase7-research/research-guide.md) | â¬œ Not Started |

### [Resource Index](resources/)

| Resource | Link |
|----------|------|
| [Linear Algebra Textbook Rankings](resources/textbook-rankings.md) | Comparison of all LA resources |
| [Video Series Index](resources/video-index.md) | 3B1B, Karpathy, Strang, Brunton |
| [Books & Textbooks](resources/books.md) | All free online resources |
| [Essential Blogs](resources/blogs.md) | colah, Neel Nanda, Jay Alammar, etc. |
| [Key Papers](resources/papers.md) | Reading list in order |
| [Courses & Programs](resources/courses.md) | MIT OCW, ARENA, Stanford, etc. |
| [Practice Problem Sources](resources/practice-problems.md) | MIT OCW, Khan Academy, Axler, Paul's Notes |

---

## How to Use This Plan

Each lesson block contains:

- **ðŸŽ¯ Core learning** â€” what we'll work through together in our sessions
- **ðŸ“º Watch** â€” videos organized as Primary â†’ Secondary â†’ Tertiary
- **ðŸ“– Read** â€” supplementary reading, similarly layered
- **ðŸ”¨ Do** â€” hands-on exercises and coding projects
- **ðŸ”— ML Connection** â€” why this matters for alignment work
- **ðŸ§  Alignment Connection** â€” direct ties to alignment research

### Recommended Learning Stack Per Concept

```
3Blue1Brown video (geometric intuition)
    â†“
MIT OCW / Strang lecture (deeper understanding, formal framework)
    â†“
MML Book chapter (ML-focused notation)
    â†“
Interactive Linear Algebra / Immersive Math (play with it)
    â†“
Exercises & Python code (make it stick)
    â†“
ML connection discussion (why it matters)
```

You don't need ALL resources for every concept. Use 3B1B as your primary and add others where you want more depth.

---

*This plan is a living document. As you progress, we'll adjust pacing, add resources, and dive deeper into areas that resonate. The goal isn't to memorize procedures â€” it's to build the geometric intuition that lets you "see" what a matrix does the way you "see" what addition does.*
